services:
  stable-diffusion:
    image: python:3.10
    container_name: stable-diffusion
    restart: unless-stopped
    # Run as root to allow apt-get install of system dependencies
    # user: "1000:1000"
    ports:
      - "0.0.0.0:7860:7860"
    volumes:
      - ./webui:/webui
    working_dir: /webui
    environment:
      # Fix for Stability-AI/stablediffusion repo being private (Dec 2025)
      # Use community fork maintained by w-e-w
      - STABLE_DIFFUSION_REPO=https://github.com/w-e-w/stablediffusion.git
      # Prevent git from prompting for credentials
      - GIT_TERMINAL_PROMPT=0
      # Fix cache directory permissions
      - HF_HOME=/webui/.cache/huggingface
      - MPLCONFIGDIR=/webui/.cache/matplotlib
      - XDG_CACHE_HOME=/webui/.cache
    command: >
      bash -c "
      apt-get update && apt-get install -y git wget libgl1 libglib2.0-0 gosu &&
      mkdir -p /webui/.cache/huggingface /webui/.cache/matplotlib &&
      useradd -u 1000 -m sduser 2>/dev/null || true &&
      chown -R 1000:1000 /webui &&
      cd /webui &&
      gosu sduser bash -c '
        if [ ! -d /webui/stable-diffusion-webui ]; then
          git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git stable-diffusion-webui &&
          cd stable-diffusion-webui &&
          ./webui.sh --skip-torch-cuda-test --exit
        fi &&
        cd /webui/stable-diffusion-webui &&
        ./webui.sh --listen --api --xformers
      '
      "
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

# Network is optional - removed to allow standalone operation
# If you want to connect to other LLM services, uncomment below:
# networks:
#   llm-network:
#     external: true
#     name: llm_default

# Stable Diffusion WebUI - AUTOMATIC1111
#
# Access web UI: http://localhost:7860
# API documentation: http://localhost:7860/docs
#
# Quick Start:
# 1. docker-compose up -d
# 2. Wait for first-time setup (installs dependencies, ~5-10 min)
# 3. Wait for model download (downloads SD 1.5, ~4GB)
# 4. Open http://localhost:7860
# 5. Enter prompt and click Generate!
#
# IMPORTANT NOTES:
# - First start takes a LONG time (installs PyTorch, clones repos, downloads model)
# - Subsequent starts are much faster
# - Uses community fork for Stability-AI repo (original went private Dec 2025)
# - Runs as root for apt-get, then switches to sduser via gosu for security
#
# Features Enabled:
# - --listen: Accept external connections
# - --api: Enable REST API
# - --xformers: Memory efficient attention (faster, less VRAM)
#
# Model Storage (inside container):
# - Checkpoints: /webui/stable-diffusion-webui/models/Stable-diffusion/
# - LoRA: /webui/stable-diffusion-webui/models/Lora/
# - VAE: /webui/stable-diffusion-webui/models/VAE/
#
# Download Models:
# Place .safetensors files in ./webui/stable-diffusion-webui/models/Stable-diffusion/
# Recommended sources:
# - Civitai: https://civitai.com/
# - HuggingFace: https://huggingface.co/models?other=stable-diffusion
#
# Popular Models for Beginners:
# - Realistic Vision v5 (photorealistic)
# - DreamShaper 8 (versatile)
# - SDXL Base (best quality, slower)
#
# Performance on RTX 4090:
# - SD 1.5 @ 512x512: ~2 seconds
# - SDXL @ 1024x1024: ~6 seconds
#
# If Out of VRAM, add --medvram to the command:
# ./webui.sh --listen --api --xformers --medvram
#
# Troubleshooting:
# - "Couldn't clone Stable Diffusion": Fixed via STABLE_DIFFUSION_REPO env var
# - "libGL.so.1 not found": Fixed via apt-get install libgl1
# - "Permission denied": Container handles this via gosu
# - Slow start: Normal for first run, installs ~2GB of dependencies
#
# Integration:
# - Use with n8n for workflow automation
# - API endpoint: http://localhost:7860/sdapi/v1/txt2img
