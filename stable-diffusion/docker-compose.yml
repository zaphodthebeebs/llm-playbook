version: '3.8'

services:
  stable-diffusion:
    image: zefie/stable-diffusion-automatic1111:1.10.1
    container_name: stable-diffusion
    restart: unless-stopped
    ports:
      - "0.0.0.0:7860:7860"
    volumes:
      # Simplified volumes - just persist data
      - ./data:/data
      - ./outputs:/outputs
    environment:
      # GPU acceleration
      - NVIDIA_VISIBLE_DEVICES=all
      # Listen on all interfaces
      - WEBUI_LAUNCH_ARGS=--listen --api --xformers
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

# Network is optional - removed to allow standalone operation
# If you want to connect to other LLM services, uncomment below:
# networks:
#   llm-network:
#     external: true
#     name: llm_default

# Stable Diffusion WebUI - AUTOMATIC1111
#
# Access web UI: http://localhost:7860
# API documentation: http://localhost:7860/docs
#
# Quick Start:
# 1. docker-compose up -d
# 2. Wait for model download (first start: ~5-10 min)
# 3. Open http://localhost:7860
# 4. Enter prompt and click Generate!
#
# Features Enabled:
# - --listen: Accept external connections
# - --api: Enable REST API
# - --xformers: Memory efficient attention (faster, less VRAM)
# - --enable-insecure-extension-access: Allow extension installation
# - --no-half-vae: Better VAE quality
# - --opt-sdp-attention: Optimized attention for RTX GPUs
#
# Model Storage:
# - Checkpoints: /workspace/llm/models/stable-diffusion/
# - LoRA: /workspace/llm/models/stable-diffusion/lora/
# - VAE: /workspace/llm/models/stable-diffusion/vae/
# - Embeddings: /workspace/llm/models/stable-diffusion/embeddings/
# - ControlNet: /workspace/llm/models/stable-diffusion/controlnet/
#
# Outputs:
# - Generated images: /workspace/llm/stable-diffusion/outputs/
#
# Download Models:
# Place .safetensors files in /workspace/llm/models/stable-diffusion/
# Recommended sources:
# - Civitai: https://civitai.com/
# - HuggingFace: https://huggingface.co/models?other=stable-diffusion
#
# Popular Models for Beginners:
# - Realistic Vision v5 (photorealistic)
# - DreamShaper 8 (versatile)
# - SDXL Base (best quality, slower)
#
# Performance on RTX 4090:
# - SD 1.5 @ 512x512: ~2 seconds
# - SDXL @ 1024x1024: ~6 seconds
#
# If Out of VRAM:
# Add --medvram to CLI_ARGS:
# - CLI_ARGS=--listen --api --xformers --medvram
#
# Troubleshooting:
# - Slow start: First launch downloads default model (~4GB)
# - GPU not detected: Check nvidia-smi and deploy.resources config
# - API not working: Ensure --api flag is in CLI_ARGS
# - Extension install fails: Check --enable-insecure-extension-access flag
#
# Integration:
# - Use with n8n for workflow automation
# - Connect to LocalAI for unified API
# - Call from LLM workflows for image generation
#
# Default model on first start:
# - Downloads SD 1.5 from HuggingFace automatically
# - You can replace with any .safetensors model after
